# MultiLayerPerceptron
Обучение многослойного перцептрона с одним скрытым слоем методом обратного распространения ошибки.

## Требования

- Использовать логистическую функцию активации (сигмоида)
- Первоначальные веса – вещественные числа от -1.0 до 1.0
- Величина коэффициента обучения: 0,05; 0.1; 0.25; 0.5; 0.75; 0.9
- Провести 6 экспериментов (с разными коэффициентами обучения)
- Количество эпох обучения: 300
- Вывод результатов обучения по эпохам – среднеквадратичная ошибка
- Построить графики по каждому эксперименту с изменением значения ошибки в процессе обучения по эпохам (по оси X – эпохи, по оси Y – значения среднеквадратичной ошибки)

## Структура сети и набор данных

Исходный набор данных доступен [тут](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data). Он содержит 150 строк (примеров) и 5 столбцов (первые 4 – признаки, последний – класс цветка, задан в виде текста, но нужно закодировать в виде чисел).
В таблице ниже заданы дополнительные условия для разных вариантов.

| | Вариант №1 | Вариант №2 | Вариант №3 |
| :---: | :---: | :---: | :---: |
| Набор данных<br>(100 примеров, по 50 на класс) | Iris-setosa<br>Iris-versicolor | Iris-versicolor<br>Iris-virginica | Iris-setosa<br>Iris-virginica |
| Количество нейронов скрытого слоя | 3 | 4 | 5 |

Для реализации был выбран *вариант №3*:

Набор данных: **Iris-setosa** и **Iris-virginica**<br>
Количество нейронов скрытого слоя: **5**

## Пример результатов обучения

![Пример графика, отражающего результаты обучения.](https://github.com/roman656/MultiLayerPerceptron/blob/main/result.png)
